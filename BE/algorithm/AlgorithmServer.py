from confluent_kafka import Consumer, Producer
import json, redis, api, time, os
import redis, json, time
from datetime import datetime, timezone, timedelta
import random
import api   # ê°™ì€ ë””ë ‰í„°ë¦¬ì˜ api.py ì„í¬íŠ¸
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
KAFKA_HOST = os.getenv('KAFKA_HOST',"localhost")
KAFKA_BOOT = os.getenv("KAFKA_BOOT", "localhost:9092")
# -------------------- â‘  Redis â†’ Python --------------------
def fetch_robot_list() -> list[tuple[str, int, int]]:
    robot_list = []
    for i in range(1, 21):
        key = f"AMR_STATUS:AMR{i:03}"
        if not r.exists(key):
            continue

        h = r.hgetall(key)
        amr_id   = h["amrId"] if "amrId" in h else f"AMR{i:03}"
        node_id  = int(h.get("currentNode", 0))           # ì—†ìœ¼ë©´ 0

        # excluded_ids = {204, 205, 212, 213, 220, 221, 228, 229}
        # robot_candidates = [i for i in list(range(1, 61)) + list(range(101, 233)) if i not in excluded_ids]
        # node_id=random.sample(robot_candidates, k=1)[0]

        loading = 1 if str(h.get("missionType", "")).upper() in ("LOADING", "CHARGING") else 0
        robot_list.append((amr_id, node_id, loading))
    return robot_list


def fetch_line_status() -> list[tuple[int, float]]:
    """
    Redis í‚¤ MISSION_PT:11~50 ì— ì €ì¥ëœ ISO8601 ë¬¸ìì—´ â†’ í˜„ì¬ì‹œê°ê³¼ì˜ ì°¨ì´ë¥¼ ì ìˆ˜ë¡œ ì‚¬ìš©
    """
    now = datetime.now()
    line_status = []
    for node in range(11, 51):
        key = f"MISSION_PT:{node}"
        if r.exists(key):
            ts_str = r.get(key)
            try:
                ts = datetime.fromisoformat(ts_str)
                elapsed = (now - ts).total_seconds()
                if 11<=node<=20 or 31<=node<=40:
                    elapsed += api.loadingTimeTable[(node-1)%10+1][node]
                line_status.append((node, elapsed))
            except Exception as e:
                print(f"âš ï¸ {key} ê°’ ë³€í™˜ ì‹¤íŒ¨: {ts_str} ({e})")
    return line_status


# -------------------- â‘¡ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ --------------------


consumer = Consumer({
    "bootstrap.servers": KAFKA_BOOT,
    "group.id": "algorithm-grp",
    "auto.offset.reset": "latest",         # ìµœì‹  ë©”ì‹œì§€ë§Œ
    "enable.auto.commit": True             # âœ… ìë™ ì»¤ë°‹
})

producer = Producer({"bootstrap.servers": KAFKA_BOOT})

r = redis.Redis(host=KAFKA_HOST, port=6379, decode_responses=True)

def publish_result(result: dict):
    print("ê²°ê³¼")
    print(result)
    producer.produce("algorithm-result", json.dumps(result))
    producer.flush()

def print_assignment(consumer, partitions):
    print("ğŸŸ¢ ì¹´í”„ì¹´ ì—°ê²° ì™„ë£Œ")



def listen_loop():
    consumer.subscribe(["algorithm-trigger"], on_assign=print_assignment)
    while True:
        msg = consumer.poll(1.0)
        if msg is None or msg.error():
            continue
        print("âœ… Received:", msg.value().decode('utf-8'))

        # ---------------- ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ----------------
        robot   = fetch_robot_list()
        jobs    = fetch_line_status()
        assign  = api.assign_tasks(robot, jobs)

        all_results = []  # âœ… ì „ì²´ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

        for (amr_id, _, _), (dest, _), type, path, cost in assign:
            if cost >= 900 or path is None:
                continue
            result = {
                "amrId"  : amr_id,
                "missionId": f"MISSION{int(dest):03}",  # ì˜ˆ: dest=80 â†’ "MISSION080"
                "missionType" : type, #ë¯¸ì…˜ íƒ€ì… "MOVING", "CHARGING"...
                "route"  : path,
                "expectedArrival" : int(cost)
            }
            all_results.append(result)
        print(all_results)
        if all_results:  # âœ… 1ê°œì˜ ë©”ì‹œì§€ë¡œ ì „ì†¡
            producer.produce("algorithm-result", json.dumps(all_results))
            producer.flush()


if __name__ == "__main__":
    #api.mapInit()
    listen_loop()
